#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬
FAISSì™€ LangChainì„ ì‚¬ìš©í•˜ì—¬ ê³µì‹œë³´ê³ ì„œë¥¼ ë²¡í„°DBì— ì €ì¥í•˜ê³  ê²€ìƒ‰
"""

import os
import json
import pickle
from typing import List, Dict, Optional, Tuple
from datetime import datetime

from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.docstore.document import Document
from config import config


class VectorStore:
    """ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, persist_directory: Optional[str] = None):
        """
        ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
        
        Args:
            persist_directory: ë²¡í„°DB ì €ì¥ ë””ë ‰í† ë¦¬ (Noneì´ë©´ configì—ì„œ ê°€ì ¸ì˜´)
        """
        self.persist_directory = persist_directory or config.VECTOR_DB_DIR
        self.metadata_path = os.path.join(self.persist_directory, config.VECTOR_DB_METADATA_FILE)
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(self.persist_directory, exist_ok=True)
        
        print("ğŸ”§ ë²¡í„° ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...")
        # í•œêµ­ì–´ ì§€ì› ì„ë² ë”© ëª¨ë¸ ì‚¬ìš© (configì—ì„œ ì„¤ì •)
        self.embeddings = HuggingFaceEmbeddings(
            model_name=config.EMBEDDING_MODEL,
            model_kwargs={'device': 'cpu'},
            encode_kwargs={'normalize_embeddings': True}
        )
        print("âœ… ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ")
        
        # í…ìŠ¤íŠ¸ ë¶„í• ê¸° ì„¤ì • (configì—ì„œ ì„¤ì •)
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=config.CHUNK_SIZE,
            chunk_overlap=config.CHUNK_OVERLAP,
            length_function=len,
            separators=["\n\n", "\n", "ã€‚", ".", " ", ""]
        )
        
        # FAISS ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ ë˜ëŠ” ìƒì„±
        self.vectorstore = self._load_or_create_vectorstore()
        
        # ë©”íƒ€ë°ì´í„° ë¡œë“œ
        self.metadata = self._load_metadata()
        
    def _load_or_create_vectorstore(self) -> FAISS:
        """FAISS ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ ë˜ëŠ” ìƒì„±"""
        index_path = os.path.join(self.persist_directory, "index.faiss")
        
        if os.path.exists(index_path):
            print(f"ğŸ“‚ ê¸°ì¡´ VectorDB ë¡œë“œ ì¤‘: {index_path}")
            try:
                vectorstore = FAISS.load_local(
                    self.persist_directory,
                    self.embeddings,
                    allow_dangerous_deserialization=True
                )
                print(f"âœ… VectorDB ë¡œë“œ ì™„ë£Œ")
                return vectorstore
            except Exception as e:
                print(f"âš ï¸  VectorDB ë¡œë“œ ì‹¤íŒ¨: {e}")
                print("   ìƒˆë¡œìš´ VectorDBë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
        
        # ìƒˆë¡œìš´ ë²¡í„°ìŠ¤í† ì–´ ìƒì„± (ë¹ˆ ë¬¸ì„œë¡œ ì´ˆê¸°í™”)
        print("ğŸ†• ìƒˆë¡œìš´ VectorDB ìƒì„± ì¤‘...")
        initial_docs = [Document(page_content="ì´ˆê¸° ë¬¸ì„œ", metadata={"type": "init"})]
        vectorstore = FAISS.from_documents(initial_docs, self.embeddings)
        print("âœ… VectorDB ìƒì„± ì™„ë£Œ")
        return vectorstore
    
    def _load_metadata(self) -> Dict:
        """ë©”íƒ€ë°ì´í„° ë¡œë“œ"""
        if os.path.exists(self.metadata_path):
            try:
                with open(self.metadata_path, 'r', encoding='utf-8') as f:
                    metadata = json.load(f)
                print(f"ğŸ“‹ ë©”íƒ€ë°ì´í„° ë¡œë“œ: {len(metadata)}ê°œ ë³´ê³ ì„œ")
                return metadata
            except Exception as e:
                print(f"âš ï¸  ë©”íƒ€ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
                return {}
        return {}
    
    def _save_metadata(self):
        """ë©”íƒ€ë°ì´í„° ì €ì¥"""
        try:
            with open(self.metadata_path, 'w', encoding='utf-8') as f:
                json.dump(self.metadata, f, ensure_ascii=False, indent=2)
            print(f"ğŸ’¾ ë©”íƒ€ë°ì´í„° ì €ì¥ ì™„ë£Œ: {len(self.metadata)}ê°œ ë³´ê³ ì„œ")
        except Exception as e:
            print(f"âš ï¸  ë©”íƒ€ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def _save_vectorstore(self):
        """ë²¡í„°ìŠ¤í† ì–´ ì €ì¥"""
        try:
            self.vectorstore.save_local(self.persist_directory)
            print(f"ğŸ’¾ VectorDB ì €ì¥ ì™„ë£Œ: {self.persist_directory}")
        except Exception as e:
            print(f"âš ï¸  VectorDB ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def get_naver_reports_from_cache(self, company_name: str = None, report_type: str = "NAVER_COMPANY", industry_keywords: List[str] = None) -> List[Dict]:
        """
        VectorDBì—ì„œ ì¦ê¶Œì‚¬ ë¦¬í¬íŠ¸ ì¡°íšŒ (ìºì‹±)
        
        Args:
            company_name: íšŒì‚¬ëª… (ì¢…ëª©ë¶„ì„ìš©)
            report_type: "NAVER_COMPANY" (ì¢…ëª©ë¶„ì„) ë˜ëŠ” "NAVER_INDUSTRY" (ì‚°ì—…ë¶„ì„)
            industry_keywords: ì‚°ì—… í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ (ì‚°ì—…ë¶„ì„ìš©)
            
        Returns:
            list: [{name, date, content, url}, ...] í˜•ì‹ì˜ ë¦¬ìŠ¤íŠ¸
        """
        if report_type == "NAVER_COMPANY":
            print(f"ğŸ” VectorDBì—ì„œ {company_name}ì˜ ì¢…ëª©ë¶„ì„ ë¦¬í¬íŠ¸ í™•ì¸ ì¤‘...")
        else:
            print(f"ğŸ” VectorDBì—ì„œ ì‚°ì—…ë¶„ì„ ë¦¬í¬íŠ¸ í™•ì¸ ì¤‘... (í‚¤ì›Œë“œ: {industry_keywords})")
        
        try:
            cached_reports = []
            
            if report_type == "NAVER_COMPANY":
                # ì¢…ëª©ë¶„ì„: íšŒì‚¬ëª…ìœ¼ë¡œ ê²€ìƒ‰
                for rcept_no, meta in self.metadata.items():
                    if rcept_no.startswith(report_type) and meta.get('company_name') == company_name:
                        cached_reports.append({
                            'name': meta.get('report_name', ''),
                            'date': meta.get('date', ''),
                            'content': meta.get('full_content', ''),
                            'url': rcept_no,
                            'rcept_no': rcept_no
                        })
            
            elif report_type == "NAVER_INDUSTRY" and industry_keywords:
                # ì‚°ì—…ë¶„ì„: ì‚°ì—… í‚¤ì›Œë“œë¡œ ê²€ìƒ‰
                for rcept_no, meta in self.metadata.items():
                    if not rcept_no.startswith(report_type):
                        continue
                    
                    report_name = meta.get('report_name', '')
                    industry_tags = meta.get('industry_keywords', [])
                    
                    # ë¦¬í¬íŠ¸ëª…ì´ë‚˜ ì‚°ì—… íƒœê·¸ì— í‚¤ì›Œë“œê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
                    matched = False
                    for keyword in industry_keywords:
                        if keyword.lower() in report_name.lower():
                            matched = True
                            break
                        if industry_tags and keyword in industry_tags:
                            matched = True
                            break
                    
                    if matched:
                        cached_reports.append({
                            'name': meta.get('report_name', ''),
                            'date': meta.get('date', ''),
                            'content': meta.get('full_content', ''),
                            'url': rcept_no,
                            'rcept_no': rcept_no
                        })
            
            if cached_reports:
                # ë‚ ì§œ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (ìµœì‹ ìˆœ)
                def parse_date(date_str):
                    try:
                        if not date_str or date_str == "ë‚ ì§œë¯¸ìƒ":
                            return "00.00.00"
                        return date_str
                    except:
                        return "00.00.00"
                
                cached_reports.sort(key=lambda x: parse_date(x['date']), reverse=True)
                
                print(f"   âœ… VectorDBì—ì„œ {len(cached_reports)}ê°œ ë¦¬í¬íŠ¸ ë°œê²¬")
                for idx, report in enumerate(cached_reports[:5], 1):
                    print(f"      [{idx}] {report['name']} ({report['date']})")
                
                return cached_reports
            else:
                if report_type == "NAVER_INDUSTRY":
                    print(f"   â„¹ï¸  VectorDBì— ì‚°ì—… í‚¤ì›Œë“œ '{', '.join(industry_keywords)}'ì™€ ê´€ë ¨ëœ ë¦¬í¬íŠ¸ ì—†ìŒ")
                else:
                    print(f"   â„¹ï¸  VectorDBì— ìºì‹œëœ ë¦¬í¬íŠ¸ ì—†ìŒ")
                return []
                
        except Exception as e:
            print(f"   âš ï¸  VectorDB ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []
    
    def check_report_exists(self, rcept_no: str) -> bool:
        """
        ë³´ê³ ì„œê°€ ë²¡í„°DBì— ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        
        Args:
            rcept_no: ì ‘ìˆ˜ë²ˆí˜¸
            
        Returns:
            bool: ì¡´ì¬ ì—¬ë¶€
        """
        exists = rcept_no in self.metadata
        if exists:
            report_info = self.metadata[rcept_no]
            print(f"âœ… VectorDBì— ë³´ê³ ì„œ ì¡´ì¬: {report_info.get('report_name')} ({report_info.get('date')})")
        return exists
    
    def get_report_from_cache(self, rcept_no: str) -> Optional[str]:
        """
        ë²¡í„°DBì—ì„œ ë³´ê³ ì„œ ì „ì²´ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°
        
        Args:
            rcept_no: ì ‘ìˆ˜ë²ˆí˜¸
            
        Returns:
            str: ë³´ê³ ì„œ ë‚´ìš© (ì—†ìœ¼ë©´ None)
        """
        if rcept_no not in self.metadata:
            return None
        
        report_info = self.metadata[rcept_no]
        print(f"ğŸ“– ìºì‹œì—ì„œ ë³´ê³ ì„œ ë¡œë“œ: {report_info.get('report_name')}")
        
        # ì €ì¥ëœ ì›ë³¸ í…ìŠ¤íŠ¸ ë°˜í™˜
        return report_info.get('full_content')
    
    def add_report(
        self,
        rcept_no: str,
        report_name: str,
        company_name: str,
        report_date: str,
        content: str,
        report_type: str = "ê³µì‹œë³´ê³ ì„œ",
        industry_keywords: List[str] = None
    ):
        """
        ë³´ê³ ì„œë¥¼ ë²¡í„°DBì— ì¶”ê°€
        
        Args:
            rcept_no: ì ‘ìˆ˜ë²ˆí˜¸
            report_name: ë³´ê³ ì„œëª…
            company_name: íšŒì‚¬ëª…
            report_date: ë³´ê³ ì„œ ë‚ ì§œ
            content: ë³´ê³ ì„œ ë‚´ìš© (Markdown í˜•ì‹)
            report_type: ë³´ê³ ì„œ ìœ í˜•
        """
        print(f"ğŸ“ VectorDBì— ë³´ê³ ì„œ ì¶”ê°€ ì¤‘: {report_name}")
        print(f"   íšŒì‚¬: {company_name}")
        print(f"   ë‚ ì§œ: {report_date}")
        print(f"   í¬ê¸°: {len(content):,}ì")
        
        try:
            # í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í• 
            print("   ğŸ”ª í…ìŠ¤íŠ¸ ì²­í¬ ë¶„í•  ì¤‘...")
            chunks = self.text_splitter.split_text(content)
            print(f"   âœ… {len(chunks)}ê°œ ì²­í¬ ìƒì„±ë¨")
            
            # Document ê°ì²´ ìƒì„±
            documents = []
            for i, chunk in enumerate(chunks):
                doc = Document(
                    page_content=chunk,
                    metadata={
                        "rcept_no": rcept_no,
                        "report_name": report_name,
                        "company_name": company_name,
                        "report_date": report_date,
                        "report_type": report_type,
                        "chunk_index": i,
                        "total_chunks": len(chunks),
                        "added_at": datetime.now().isoformat()
                    }
                )
                documents.append(doc)
            
            # ë²¡í„°ìŠ¤í† ì–´ì— ì¶”ê°€
            print("   ğŸ”„ ë²¡í„° ì„ë² ë”© ìƒì„± ë° FAISS ì¸ë±ìŠ¤ì— ì¶”ê°€ ì¤‘...")
            self.vectorstore.add_documents(documents)
            print("   âœ… ë²¡í„° ì„ë² ë”© ì™„ë£Œ")
            
            # ë©”íƒ€ë°ì´í„° ì €ì¥
            self.metadata[rcept_no] = {
                "report_name": report_name,
                "company_name": company_name,
                "date": report_date,
                "report_type": report_type,
                "num_chunks": len(chunks),
                "content_length": len(content),
                "full_content": content,  # ì›ë³¸ í…ìŠ¤íŠ¸ë„ ì €ì¥
                "industry_keywords": industry_keywords if industry_keywords else [],  # ì‚°ì—… í‚¤ì›Œë“œ
                "added_at": datetime.now().isoformat()
            }
            
            # ë””ìŠ¤í¬ì— ì €ì¥
            self._save_vectorstore()
            self._save_metadata()
            
            print(f"âœ… VectorDB ì¶”ê°€ ì™„ë£Œ: {report_name}")
            
        except Exception as e:
            print(f"âŒ VectorDB ì¶”ê°€ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
    
    def search_similar_reports(
        self,
        query: str,
        company_name: Optional[str] = None,
        k: int = 5
    ) -> List[Tuple[Document, float]]:
        """
        ìœ ì‚¬í•œ ë³´ê³ ì„œ ê²€ìƒ‰
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            company_name: íšŒì‚¬ëª… (ì„ íƒì‚¬í•­, ì§€ì •í•˜ë©´ í•´ë‹¹ íšŒì‚¬ë¡œ í•„í„°ë§)
            k: ë°˜í™˜í•  ë¬¸ì„œ ìˆ˜
            
        Returns:
            List[Tuple[Document, float]]: (ë¬¸ì„œ, ìœ ì‚¬ë„ ì ìˆ˜) ë¦¬ìŠ¤íŠ¸
        """
        print(f"ğŸ” VectorDB ê²€ìƒ‰ ì¤‘: '{query[:50]}...'")
        if company_name:
            print(f"   íšŒì‚¬ í•„í„°: {company_name}")
        
        try:
            # ìœ ì‚¬ë„ ê²€ìƒ‰
            results = self.vectorstore.similarity_search_with_score(query, k=k*3)  # í•„í„°ë§ ê³ ë ¤í•´ì„œ ë” ë§ì´ ê°€ì ¸ì˜´
            
            # íšŒì‚¬ëª… í•„í„°ë§
            if company_name:
                filtered_results = []
                for doc, score in results:
                    if doc.metadata.get('company_name', '').upper() == company_name.upper():
                        filtered_results.append((doc, score))
                results = filtered_results[:k]
            else:
                results = results[:k]
            
            print(f"âœ… {len(results)}ê°œ ê²°ê³¼ ë°œê²¬")
            
            # ê²°ê³¼ ì¶œë ¥
            for i, (doc, score) in enumerate(results, 1):
                meta = doc.metadata
                print(f"   [{i}] {meta.get('report_name')} ({meta.get('report_date')})")
                print(f"       ìœ ì‚¬ë„: {score:.4f}, ì²­í¬: {meta.get('chunk_index')}/{meta.get('total_chunks')}")
            
            return results
            
        except Exception as e:
            print(f"âŒ VectorDB ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return []
    
    def get_all_reports_for_company(self, company_name: str) -> List[Dict]:
        """
        íŠ¹ì • íšŒì‚¬ì˜ ëª¨ë“  ë³´ê³ ì„œ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        
        Args:
            company_name: íšŒì‚¬ëª…
            
        Returns:
            List[Dict]: ë³´ê³ ì„œ ì •ë³´ ë¦¬ìŠ¤íŠ¸
        """
        reports = []
        for rcept_no, info in self.metadata.items():
            if info.get('company_name', '').upper() == company_name.upper():
                reports.append({
                    'rcept_no': rcept_no,
                    'report_name': info.get('report_name'),
                    'date': info.get('date'),
                    'report_type': info.get('report_type'),
                    'num_chunks': info.get('num_chunks'),
                    'added_at': info.get('added_at')
                })
        
        # ë‚ ì§œ ìˆœìœ¼ë¡œ ì •ë ¬ (ìµœì‹ ìˆœ)
        reports.sort(key=lambda x: x.get('date', ''), reverse=True)
        
        print(f"ğŸ“Š {company_name}ì˜ ë³´ê³ ì„œ {len(reports)}ê°œ ë°œê²¬")
        return reports
    
    def delete_report(self, rcept_no: str):
        """
        ë³´ê³ ì„œ ì‚­ì œ (ë©”íƒ€ë°ì´í„°ë§Œ ì‚­ì œ, ë²¡í„°ëŠ” ì¬êµ¬ì¶• í•„ìš”)
        
        Args:
            rcept_no: ì ‘ìˆ˜ë²ˆí˜¸
        """
        if rcept_no in self.metadata:
            report_name = self.metadata[rcept_no].get('report_name')
            del self.metadata[rcept_no]
            self._save_metadata()
            print(f"ğŸ—‘ï¸  ë³´ê³ ì„œ ì‚­ì œ ì™„ë£Œ: {report_name}")
            print("   âš ï¸  ì£¼ì˜: ë²¡í„° ì¸ë±ìŠ¤ëŠ” ì¬êµ¬ì¶•ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        else:
            print(f"âŒ ë³´ê³ ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {rcept_no}")
    
    def rebuild_index(self):
        """
        ë²¡í„° ì¸ë±ìŠ¤ ì¬êµ¬ì¶• (ë©”íƒ€ë°ì´í„° ê¸°ë°˜)
        """
        print("ğŸ”„ ë²¡í„° ì¸ë±ìŠ¤ ì¬êµ¬ì¶• ì¤‘...")
        
        all_documents = []
        for rcept_no, info in self.metadata.items():
            content = info.get('full_content', '')
            if not content:
                continue
            
            chunks = self.text_splitter.split_text(content)
            
            for i, chunk in enumerate(chunks):
                doc = Document(
                    page_content=chunk,
                    metadata={
                        "rcept_no": rcept_no,
                        "report_name": info.get('report_name'),
                        "company_name": info.get('company_name'),
                        "report_date": info.get('date'),
                        "report_type": info.get('report_type'),
                        "chunk_index": i,
                        "total_chunks": len(chunks),
                        "added_at": info.get('added_at')
                    }
                )
                all_documents.append(doc)
        
        if all_documents:
            print(f"   ì´ {len(all_documents)}ê°œ ì²­í¬ ì¬êµ¬ì¶• ì¤‘...")
            self.vectorstore = FAISS.from_documents(all_documents, self.embeddings)
            self._save_vectorstore()
            print("âœ… ë²¡í„° ì¸ë±ìŠ¤ ì¬êµ¬ì¶• ì™„ë£Œ")
        else:
            print("âš ï¸  ì¬êµ¬ì¶•í•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    def get_stats(self) -> Dict:
        """
        ë²¡í„°DB í†µê³„ ì •ë³´
        
        Returns:
            Dict: í†µê³„ ì •ë³´
        """
        total_reports = len(self.metadata)
        total_chunks = sum(info.get('num_chunks', 0) for info in self.metadata.values())
        total_size = sum(info.get('content_length', 0) for info in self.metadata.values())
        
        companies = set(info.get('company_name') for info in self.metadata.values())
        
        stats = {
            "total_reports": total_reports,
            "total_chunks": total_chunks,
            "total_size_chars": total_size,
            "num_companies": len(companies),
            "companies": list(companies),
            "storage_path": self.persist_directory
        }
        
        return stats
    
    def print_stats(self):
        """í†µê³„ ì •ë³´ ì¶œë ¥"""
        stats = self.get_stats()
        
        print("\n" + "="*60)
        print("ğŸ“Š VectorDB í†µê³„")
        print("="*60)
        print(f"ì´ ë³´ê³ ì„œ ìˆ˜: {stats['total_reports']}ê°œ")
        print(f"ì´ ì²­í¬ ìˆ˜: {stats['total_chunks']}ê°œ")
        print(f"ì´ ë°ì´í„° í¬ê¸°: {stats['total_size_chars']:,}ì")
        print(f"íšŒì‚¬ ìˆ˜: {stats['num_companies']}ê°œ")
        if stats['companies']:
            print(f"íšŒì‚¬ ëª©ë¡: {', '.join(stats['companies'])}")
        print(f"ì €ì¥ ê²½ë¡œ: {stats['storage_path']}")
        print("="*60 + "\n")
    
    def reset_database(self) -> bool:
        """
        VectorDB ì™„ì „ ì´ˆê¸°í™” (ëª¨ë“  ë°ì´í„° ì‚­ì œ)
        
        Returns:
            bool: ì„±ê³µ ì—¬ë¶€
        """
        try:
            print(f"ğŸ—‘ï¸  VectorDB ì´ˆê¸°í™” ì¤‘...")
            
            # 1. ë©”íƒ€ë°ì´í„° ì´ˆê¸°í™”
            self.metadata = {}
            self._save_metadata()
            print(f"   âœ… ë©”íƒ€ë°ì´í„° ì´ˆê¸°í™” ì™„ë£Œ")
            
            # 2. ì €ì¥ëœ íŒŒì¼ë“¤ ì‚­ì œ
            faiss_index_path = os.path.join(self.persist_directory, "index.faiss")
            faiss_pkl_path = os.path.join(self.persist_directory, "index.pkl")
            
            if os.path.exists(faiss_index_path):
                os.remove(faiss_index_path)
                print(f"   âœ… FAISS ì¸ë±ìŠ¤ íŒŒì¼ ì‚­ì œ")
            
            if os.path.exists(faiss_pkl_path):
                os.remove(faiss_pkl_path)
                print(f"   âœ… FAISS PKL íŒŒì¼ ì‚­ì œ")
            
            # 3. VectorStore ì¬ì´ˆê¸°í™”
            self.vectorstore = self._load_or_create_vectorstore()
            
            print(f"âœ… VectorDB ì´ˆê¸°í™” ì™„ë£Œ!")
            return True
            
        except Exception as e:
            print(f"âŒ VectorDB ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    print("ğŸ§ª VectorStore í…ŒìŠ¤íŠ¸ ì‹œì‘\n")
    
    # VectorStore ì´ˆê¸°í™”
    vs = VectorStore()
    
    # í†µê³„ ì¶œë ¥
    vs.print_stats()
    
    print("âœ… VectorStore í…ŒìŠ¤íŠ¸ ì™„ë£Œ")

